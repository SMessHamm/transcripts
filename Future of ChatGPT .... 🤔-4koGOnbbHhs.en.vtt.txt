 on November 30 Chad GPT was launched and  within a week it crossed 1 million users  to give you a contact Netflix took 41  months Facebook took 10 months Instagram  took two months and here the chat GPT  took just five days it clearly shows  that there is a demand for human-like  chatbot and every major publication is  talking about it of how scary good it is  and it is capable of answering questions  on a wide variety of topic and trust me  the AI himself said me that when I asked  him it is able to debug a program write  a script a song a rap a research paper  or whatever you can think of and this  made me thinking that what make this  model so good at so many things well it  is a large model built on top of gpd3  with almost 175 billion parameters which  is around 100 times more than its  previous generation gpt2 to give you an  account of how huge this model is it to  thousands of worlds fastest GPU 34 trays  to train this Beast which roughly  accounts for 4 million dollars in just  Computing cost but why are we seeing  such AI breakthroughs like GPT 3 Dali 2  happen in past few years only don't get  me wrong the AI research has been going  on for decades and we are here because  of it but my point is that now in order  to create a model with billions or  trillions of parameter we need a lot of  computing and according to the Morris  law the campaigning power is doubling  every two years and at the same time the  cost of computing power would cut down  in half and this decade has been the  golden time where we have seen silicon  chip with high performance and high  efficiency and especially the gpus are  getting exponentially powerful which has  enabled researchers to build such large  model  as the CEO of open AI the organization  behind chat GPT said  I'll start with like the higher cert  things I I think language models are  going to go just much much further than  people think  um and we're like very excited to see  what happens there  um I think it's like what a lot of  people say about you know running out of  compute running out of data like that's  all true but I think there's so much  algorithmic progress to come  um that  that we're gonna have like a very  exciting time so we will see some major  improvements in the coming years  like such air models are great at  replicating what already has been done  but it is unable to create a new  knowledge like if I ask an AI to create  a time machine it will be unable to do  so because we humans are struggling to  answer that question but it is great at  applying the knowledge like recently the  Dali 2 AI was able to recreate painting  style of famous painter by applying the  knowledge it has learned in the training  phase  now in the coming years we will see more  startup creating AI tools or producing  such am models as selfies to increase  the productivity in job  and for the AI we might see some AI  models with an ability to create  knowledge that we human struggle with  the open air is focused on solving this  problem so we might see such models in  the next decade and finally there will  be some Hope For The Time Machine  [Music]  foreign  [Music]