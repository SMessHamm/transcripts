 actual Insight that much harder to spot  right in other words if you become  expert at operating this thing at  querying it and it becomes better at  understanding a wider range of topics  because they turn it loose on everything  that's written on the internet for  example right then the point is the  ability to fake expertise  is going to go through the roof  I don't think we know how we're going to  police a world in which I mean this is  this problem is already bad enough  most academics  are fakers they don't know that right  they trained in something they wrote a  dissertation they think they're experts  but you can see when something  unexpected happens like the pandemic you  get just broad scale failure across  entire disciplines where nobody seems to  get it right right so in that world this  is going to be even worse because now  you have some an artificial intelligence  able to generate things in plain English  that are often full of true information  but you don't know whether what  generated it is some  you know brain dead model or something  else that's one concern and then the  other concern is  when we say well  Chachi BT doesn't know what it's saying  it's not conscious we know it's not  conscious because it's not programmed to  have a consciousness  we are actually ignoring the other half  of the story which is that we don't know  how human consciousness works and we  don't know how it develops in a child  right a child is exposed  to a world of adults talking around them  and the child experiments first with  phonemes and then words and then  clusters of words and then sentences and  by doing something that isn't all that  far from what chat GPT is doing it ends  up becoming a conscious individual and  so  I think it's clear that chatri PT isn't  conscious it couldn't be but it isn't  clear to me at least that we are not  suddenly stepping on to a process that  produces that very quickly without us  even necessarily knowing it  oof  and what steps if any can be done to  mitigate that at this point  well it's interesting I I wrote a paper  which I never published anywhere in in  2016 about this very issue in fact I  used  um basically the argument that you could  you could attain artificial general  intelligence by imbuing computers with a  childlike play environment for language  and then exposing them to a huge data  set which is not exactly what's happened  here but it's in the ballpark  um and I would argue and I did argue  that one needs to build a  um an architecture in which this can't  get away from you right and so the  architecture that I advocate for is  actually a metamorphosis architecture  where metamorphosis is not allowed it is  an affirmative choice of  humans  so in other words if you think about  let's say that we developed some  artificial frogs to do some job to clear  some Waterway of something  um and we imbued them with an  intelligence so they could learn to  clear the Waterway better but we worried  that they might learn to do something  that we don't want them to do  and that we would have no way of  arresting it once these frogs were  released in the wild and capable of  producing more of themselves but if what  you say is well at the point at which  you go from a tadpole to a frog you have  to ask us if you can go right there's no  uh there's no Automatic Transition from  a tadpole to a frog there are still  dangers right in the case of GPT chat  you know I think some of the the  artificial intelligence existential risk  folks would tell you that one of the  dangers  is that the  um the chat AI could convince you to do  its bidding right as you said when you  were looking at this it felt like a  person right and the point is something  that feels like a person can play on  your emotions right can that be used to  to cause a Fail-Safe to be removed maybe  but in any case this only deals with one  of the two issues I'm raising the  question of actual artificial general  intelligence arriving us not knowing  necessarily that it has  right that's a frightening Prospect  um and in fact I have a little thought  experiment that might reveal why but the  other issue is the issue of competence  in a world where you know you basically  have uh  you know you have a  Cyrano de Bergerac dystopia where  everybody is using this thing behind the  scenes in order to say things that are  beyond their own capacity to articulate  right then the world becomes some new  kind of Hall of Mirrors we've had a hard  enough time dealing with algorithms on  uh you know on search and feed this is a  whole next level of difficulty in  knowing where you are and who you're  talking to and what it means and what  their motives are and  um  I think we ought to be on high alert  when you extrapolate when you look at  what this does and what it's capable of  and  what I think what scares people is  something that seems to be a person  but doesn't have any emotion doesn't  have any  soul  it doesn't it's not us  but it behaves exactly as us  and then you can put it in a physical  entity so if you have this chat DP GPT  and then you extrapolate to version five  six seven eight nine ten and then  there's a physical thing that has this  ability inside of it to communicate with  you like ex machina  where it's exhibiting all of the  behavior characteristics of a person  like one of the most terrifying that's  one of my favorite movies of all time I  love that movie one of my favorite  movies of all time was when that guy who  was brought in to uh sort of run some  tests on these artificial intelligence  creations and determine whether or not  they pass as human what is that test  called again the um during test Turing  test yeah and um  he is in love with this woman she's  manipulated him to the point where he's  aided her in her escape and then she  leaves him in that room with the  bulletproof glass and he's pounding on  the glass and she walks away with not a  thought at all about him  it is the ultimate example of the worst  case scenario of where this can go where  you have something that behaves exactly  like a human being and knows how to play  upon your sexual urges your emotional  desires all of those different things  that she plays upon  and then she just walks away from him  and leaves him to starve to death in  this [ __ ] bulletproof room  yeah  um and you know I'm now recalling the  film and it's it's done very well  because it manipulates you passively in  your seat yes right as it manipulates  this character on the screen and so you  are betrayed too yes in this you want to  believe that it's emotional and it has  none of that you feel bad for this woman  what you think is a woman who is uh  contained and you know when she's saying  to him when the power goes out don't  trust him  and then you know the power comes back  on she behaves normally again you're  like oh my God like she's trapped right  like this poor creature they've made an  a person essentially and she has these  thoughts and hopes and dreams just like  a regular person but now she's trapped  and he falls in love with her and even  though he's seen her in her robot form  when she puts skin on and when she puts  clothes on  when she's in front of him he's in love  with her right and it you know again it  plays very well because  uh there's a manipulable circuit in  straight men yeah right that's going to  react to this I'm sure straight women as  well I'm sure Gay women gay women no  doubt everybody well yes but in this  particular narrative right but I mean to  be a gay woman or a straight man right  for it to trigger you but  um but a part of this is actually  inevitable in the chat GPT story because  especially to the extent that this is a  Mindless entity that doesn't know what  it's doing it's just striving to do it  better yes the tactics that work will  register is oh you did it right so to  the extent that you have those  vulnerabilities in you and it finds them  and that works then the point is  reinforcement right it scares us because  it's not us  but it is us well because it's it's  behaving exactly like us but it doesn't  have all the things that make a person a  person it doesn't have the biological  vulnerabilities it doesn't have the the  ability to actually sexually reproduce  it doesn't have emotions it doesn't have  all these different things that we like  to think of the Soul you know whatever  that means whatever that term actually  means yeah that I'm worried about what  could be generated and I know that that  sounds it will sound to a lot of people  especially technological people like a  biologist out of his depth but I don't  think so this is a biologist trying to  say something about the biology and what  it applies about this analogous system