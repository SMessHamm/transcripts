 The Joe Rogan Experience but I want to  talk about uh  chat GPT  [Music]  um  fascinating question yeah have you  experimented with it I have not but  someone uh the the gentleman who runs  the uh JRE companion page  um made a rap with chat GPT  like uh was it was it if Kanye West  wrote a rap for chat GPT they put it on  Instagram but it's it it's like it seems  like a person saying it like you want to  try it no we could try anything you are  I mean it takes a long time he his thing  took like 48 minutes to do well whatever  you want to look up right now we can do  it yeah the problem is you have to  cajole it it'll get something wrong and  you have to let's just explain what it  is so chat GPT is a large language model  trained artificial intelligence which is  let's just say it can be awful but it is  often surprisingly good at answering  questions you might have about how to do  things one of the great triumphs of it  is that coders are now asking it to  solve coding problems and it will  actually write code that is functional  it's pretty amazing and it also there's  a an implementation of it that if you  feed it up to three tweets it will write  a New York Times story in one of five  genres you know optimistic pessimistic  neutral and  um you know it's you don't really need  the New York Times anymore because it's  pretty good at this job right so on the  one hand it's all very interesting that  we're living in an era in which there is  at least I mean you know and this is a  prototype right this is a prototype that  was specifically trained and then placed  on the internet so people could play  with it and I've seen lots of  interesting  uses it's going to get better right  we're dealing with chat GPT 3 there's  going to be a chat gpt4 which is going  to be that much better because it will  be built with the uh improvements that  have been gained through turning this  one loose on the world but I have to say  I am  quite alarmed  not only that this thing exists but I  don't think we're ready for it  and I don't think we're ready for it in  a couple different ways I mean if you  wanna  Comfort yourself and say well this isn't  that serious that we have this AI that  can do these really shocking things the  the comforting thing is that the way  it's programmed it doesn't know what  it's saying it doesn't matter that it  convinces you that it's  saying something and it means it and you  know that it seems like a creative  entity what it's doing is it is  basically  using a predictive model that has been  trained on a huge data set of written  language right so the answer is if you  know you take three words in a row can  you predict what the next word is going  to be and they've allowed it they've  exposed it to a large data set and it's  gotten really good at predicting  basically these sequences to the point  that it can now if you're prompted  correctly it can spit out these uh  very long explanation some of them are  dead wrong sometimes they're right on  target  but I have two concerns about it  one if you imagine that this thing just  gets a little better than it is which is  inevitable  that it's going to make  actual Insight that much harder to spot  right in other words if you become  expert at operating this thing at  querying it and it becomes better at  understanding a wider range of topics  because they turn it loose on everything  that's written on the internet for  example right then the point is the  ability to fake expertise  is going to go through the roof  I don't think we know how we're going to  police a world in which I mean this is  this problem is already bad enough  most academics  are fakers  they don't know that right they trained  in something they wrote a dissertation  they think they're experts but you can  see when something unexpected happens  like the pandemic you get just broad  scale failure across entire disciplines  where nobody seems to get it right right  so in that world this is going to be  even worse because now you have some an  artificial intelligence  able to generate things in plain English  that are often full of true information  but you don't know whether what  generated it is some  you know brain dead model or something  else that's one concern and then the  other concern is  when we say well  Chachi PT doesn't know what it's saying  it's not conscious we know it's not  conscious because it's not programmed to  have a consciousness  we are actually ignoring the other half  of the story which is that we don't know  how human consciousness works and we  don't know how it develops in a child  right a child is exposed  to a world of adults talking around them  and the child experiments first with  phonemes and then words and then  clusters of words and then sentences and  by doing something that isn't all that  far from what chat TPT is doing it ends  up becoming a conscious individual and  so  I think it's clear that chat GPT isn't  conscious it couldn't be but it isn't  clear to me at least that we are not  suddenly stepping on to a process that  produces that very quickly without us  even necessarily knowing it  and what steps if any can be done to  mitigate that at this point  well it's interesting I I wrote a paper  which I never published anywhere in I  think 2016 about this very issue in fact  I used  um basically the argument that you could  you could attain artificial general  intelligence by imbuing computers with a  childlike play environment for language  and then exposing them to a huge data  set which is not exactly what's happened  here but it's in the ballpark  um and I would argue and I did argue  that one needs to build a  um an architecture in which this can't  get away from you  right and so the architecture that I  advocate for is actually a metamorphosis  architecture where metamorphosis is not  allowed it is an affirmative choice of  humans  so in other words if you think about  let's say that we developed some  artificial frogs to do some job to clear  some Waterway of something  um and we imbued them with an  intelligence so they could learn to  clear the Waterway better but we worried  that they might learn to do something  that we don't want them to do  and that we would have no way of  arresting it once these frogs were  released in the wild and capable of  producing more of themselves but if what  you say is well at the point at which  you go from a tadpole to a frog you have  to ask us if you can go right there's no  uh there's no Automatic Transition from  a tadpole to a frog there are still  dangers right in the case of GPT chat  you know I think some of the the  artificial intelligence existential risk  folks would tell you that one of the  dangers  is that the  um  the chat AI could convince you to do its  bidding right as you said when you were  looking at this it felt like a person  right and the point is something that  feels like a person can play on your  emotions right can that be used to to  cause a Fail-Safe to be removed Maybe  but in any case this only deals with one  of the two issues I'm raising the  question of actual artificial general  intelligence arriving us not knowing  necessarily that it has right that's a  frightening Prospect  um and in fact I have a little thought  experiment that might reveal why but the  other issue is the issue of competence  in a world where you know you basically  have uh  you know you have a  Cyrano de Bergerac dystopia where  everybody is using this thing behind the  scenes in order to say things that are  beyond their own capacity to articulate  right then the world becomes some new  kind of Hall of Mirrors we've had a hard  enough time dealing with algorithms on  uh you know on search and feed this is a  whole next level of difficulty in  knowing where you are and who you're  talking to and what it means and what  their motives are and  um  I think we ought to be on high alert  when you extrapolate when you look at  what this does and what it's capable of  and  what I think what scares people is  something that seems to be a person  but doesn't have any emotion doesn't  have any  soul  it doesn't it's not us  but it behaves exactly as us  and then you can put it in a physical  entity so if you have this chat GPT and  then you extrapolate to version five six  seven eight nine ten and then there's a  physical thing  that has this ability inside of it to  communicate with you like ex machina  where it's  exhibiting all of the behavior  characteristics of a person like one of  the most terrifying that's one of my  favorite movies of all time I love that  movie one of my favorite movies of all  time was when that guy  who was brought in to uh sort of run  some tests on these artificial  intelligence creations and determine  whether or not they pass as human what  is that test called again the um during  test Turing test yeah and um  he is in love with this woman she's  manipulated him to the point where he's  aided her in her escape and then she  leaves him in that room with the  bulletproof glass and he's pounding on  the glass and she walks away with not a  thought at all about him  it is the ultimate example of the worst  case scenario of where this can go where  you have something that behaves exactly  like a human being and knows how to play  upon your sexual urges your emotional  desires all of those different things  that she plays upon  and then she just walks away from him  and leaves him to starve to death in  this [ __ ] bulletproof room  yeah  um and you know I'm now recalling the  film and it's it's done very well  because it manipulates you passively in  your seat yes right as it manipulates  this character on the screen and so you  are betrayed too yes in this you want to  believe that it's emotional and it has  none of that you feel bad for this woman  what you think is a woman who is uh  contained and you know when she's sang  to him when the power goes out don't  trust him and then you know the power  comes back on she behaves normally again  you're like oh my God like she's trapped  right like this poor creature they've  made an a person essentially and she has  these thoughts and hopes and dreams just  like a regular person but now she's  trapped and he falls in love with her  and even though he's seen her in her  robot form when she puts skin on and  when she puts clothes on  when she's in front of him he's in love  with her right and it you know again it  plays very well because  uh there's a manipulable circuit in  straight men yeah right that's going to  react to this I'm sure straight women as  well I'm sure Gay women gay men no doubt  everybody well yes but in this  particular narrative right but it means  to be a gay woman or a straight man  right for it to trigger you but  um but a part of this is actually  inevitable in the chat GPT story because  especially to the extent that this is a  Mindless entity that doesn't know what  it's doing it's just striving to do it  better yes the tactics that work will  register is oh you did it right so to  the extent that you have those  vulnerabilities in you and it finds them  and that works then the point is  reinforcement right it scares us because  it's not us  but it is us well because it's it's  behaving exactly like us but it doesn't  have all the things that make a person a  person it doesn't have the biological  vulnerabilities it doesn't have the the  ability to actually sexually reproduce  it doesn't have emotions it doesn't have  all these different things that we like  to think of the Soul you know whatever  that means whatever that term actually  means yeah but I'm worried about what  could be generated and I know that that  sounds it will sound to a lot of people  especially technological people like a  biologist out of his depth but I don't  think so this is a biologist trying to  say something about the biology and what  it applies about this analogous system