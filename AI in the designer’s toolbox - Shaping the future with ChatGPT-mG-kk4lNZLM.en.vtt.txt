 Emmet Connolly: Hi, everybody. Welcome to the&nbsp; Inside Intercom podcast. I’m very excited today to&nbsp;&nbsp; be joined by Molly and Gustavs from the Intercom&nbsp; product design team. Since the launch of ChatGPT&nbsp;&nbsp; a few weeks ago, there have been a lot of heated&nbsp; discussions, a lot of idle random speculation, and&nbsp;&nbsp; a lot of armchair corridor backing about what it&nbsp; all means. Most of it, I would say, is from people&nbsp;&nbsp; who have not actually worked directly with the&nbsp; technology at all, which is why I’m very excited&nbsp;&nbsp; to talk to Molly and Gustavs today. Because Molly&nbsp; and Gustavs are two of the fairly teeny tiny&nbsp;&nbsp; minority of the entire world who have actually&nbsp; done real applied product design work with&nbsp;&nbsp; ChatGPT and related technologies. I mean, actually&nbsp; using it to integrate with products and solve real&nbsp;&nbsp; product issues for customers with real products&nbsp; operating at scale. So, Molly and Gustavs,&nbsp;&nbsp; welcome to the show. Maybe you’d like to introduce&nbsp; yourselves very briefly. Molly, do you want to go? Molly Mahar: Sure, sure.&nbsp; I’m Molly Mahar. I’m a staff&nbsp;&nbsp; designer here at Intercom. I’m fairly new.&nbsp; I’m embedded with the machine learning team,&nbsp;&nbsp; with a team of engineers, and&nbsp; we do a lot of prototyping. Gustavs Cirulis: Hey, I’m Gustav.&nbsp; I’m a principal product designer,&nbsp;&nbsp; and I’ve been here for a bit longer than&nbsp; Molly. I’ve been sort of all over the place,&nbsp;&nbsp; but at the moment, I’m working on the growth team. Emmet: Today, we’re going to talk about AI and&nbsp; large language models like ChatGPT. Specifically,&nbsp;&nbsp; about what they mean for design and designers. We&nbsp; will talk a bit about what new opportunities are&nbsp;&nbsp; available to designers, specifically with this&nbsp; new technology, what it’s been like for you or&nbsp;&nbsp; what’s been different about working with AI versus&nbsp; traditional products, and some of the challenges&nbsp;&nbsp; that you’ve encountered as you’ve started to&nbsp; design these AI-powered features. We might&nbsp;&nbsp; even get into some ill-advised prediction-making&nbsp; at some point. But let’s start with the basics.&nbsp;&nbsp; Molly, what was your first reaction when ChatGPT&nbsp; landed on the scene and made quite a big splash&nbsp;&nbsp; just a few weeks ago? You’ve been working with&nbsp; AI and NML systems for quite a while before that. Molly: Well, first, I got bombarded by a&nbsp; number of screenshots on Slack and started&nbsp;&nbsp; seeing them come in from people all around&nbsp; the company and on Twitter and everything.&nbsp;&nbsp; I tried it out and was like, “This is&nbsp; very cool. This is also very smart.”&nbsp;&nbsp; Large language models have been around for a&nbsp; while, but now they’ve put a UI on their API.&nbsp;&nbsp; And so, more people everywhere are able to use&nbsp; them without having to be a developer or anything,&nbsp;&nbsp; which I think is pretty awesome and shows&nbsp; just how excited people were about them.&nbsp;&nbsp; I started playing with it,&nbsp; and it’s really powerful. You can ask it a lot of questions, you can&nbsp; follow up. It feels really amazing. It feels like&nbsp;&nbsp; somewhat of a conversation. Then we started, as a&nbsp; team, digging into it to try and stress-test it.&nbsp;&nbsp; And I felt like I was starting to see the hype.&nbsp; It reminded me of behavioral economics in college&nbsp;&nbsp; and the Dunning-Kruger effect, where you’re&nbsp; incompetent but overconfident. And it felt like&nbsp;&nbsp; that sometimes. This ChatGPT is so much better&nbsp; at bullshitting than I am. I’m amazed at it.&nbsp;&nbsp; And so, I went through a&nbsp; wave of feelings about it.&nbsp;&nbsp; I wonder if it would be useful&nbsp; to give a quick overview of LLMs. Emmet: I think so. I think, for a lot of people,&nbsp; there’s this association with ChatGPT as the AI&nbsp;&nbsp; everybody is talking about. So, would you mind&nbsp; explaining in layperson’s terms what ChatGPT&nbsp;&nbsp; is and how that relates to other terms like large&nbsp; language models that folks might have heard about? Molly: Yeah, I’ll do my best. So, large&nbsp; language models, LLMs, for short, are&nbsp;&nbsp; models trained on a huge corpus of public text&nbsp; from everywhere – books, the internet, multimodal&nbsp;&nbsp; sources, I think, sometimes. Billions and billions&nbsp; and billions of pieces of data inside. And they’re&nbsp;&nbsp; often trained with human feedback along the&nbsp; way. I think that leads to why you can have&nbsp;&nbsp; this conversation with ChatGPT – you can give it&nbsp; feedback, and it’ll actually respond to that and&nbsp;&nbsp; change its responses. LLMs have been around for a&nbsp; while, getting better and faster and faster. The&nbsp;&nbsp; amazing thing about ChatGPT is that, as a&nbsp; person, I can actually use it. And second,&nbsp;&nbsp; it’s actually really, really&nbsp; good. ChatGPT is the front end,&nbsp;&nbsp; basically, and I’m simplifying this&nbsp; a bit, but it’s the front end for&nbsp;&nbsp; a large language model API that OpenAI has in&nbsp; the background. And they have a number of these. There are a lot of other companies that also have&nbsp; large language models. Google’s working on LaMDA,&nbsp;&nbsp; and there are other companies. And so,&nbsp; we might say ChatGPT here today, but&nbsp;&nbsp; we’re referring to this technology in general.&nbsp; We’re actually working with the APIs behind it,&nbsp;&nbsp; not with ChatGPT, which is only&nbsp; available through the UI right now. Emmet: Yeah. And I think one of the things that’s&nbsp; interesting about ChatGPT is that, in some ways,&nbsp;&nbsp; it’s not that new from a technical point of view.&nbsp; ChatGPT is an app built using GPT-3.5 built by a&nbsp;&nbsp; company called OpenAI. But GPT-3.5 has been around&nbsp; for a while – several months, right, Molly? So,&nbsp;&nbsp; I’m curious. Gustavs, what was your reaction? Why&nbsp; do you think there’s a different reaction to what&nbsp;&nbsp; we’re seeing with ChatGPT versus the underlying&nbsp; tech, which was available for some time? Gustavs: I think the big difference is that the&nbsp; presentation is like a conversation where you can&nbsp;&nbsp; ask follow-up questions and go deeper. Before,&nbsp; it was just kind of, “Hey, generate me this&nbsp;&nbsp; poem about whatever.” Now, you can&nbsp; have a back-and-forth conversation.&nbsp;&nbsp; That’s how humans interact with each other. So,&nbsp; it’s way more familiar than giving it a one-off&nbsp;&nbsp; prompt. When I was playing around with ChatGPT&nbsp; when it just came out, it felt like magic.&nbsp;&nbsp; It was really hard to believe this exists.&nbsp; And I just kept playing around with it,&nbsp;&nbsp; talking about different topics, and it felt like&nbsp; having an on-demand personal tutor that knows&nbsp;&nbsp; everything about everything. It talked about&nbsp; all sorts of things about technology, history,&nbsp;&nbsp; psychology, and even comedy. Turns out,&nbsp; it’s really good at coming up with standup&nbsp;&nbsp; comedy if you give it a good prompt.&nbsp; It was really fun to do that as well. Emmet: You’ve both spent several weeks working&nbsp; with this now. We all had that very impressive&nbsp;&nbsp; initial reaction, but having spent a few weeks&nbsp; trying to apply this to real customer problems,&nbsp;&nbsp; maybe wrestling with directly applying it&nbsp; somehow, does it stand up to the hype, Gustavs? Gustavs: Yeah. As soon as ChatGPT came out, we&nbsp; were really impressed and realized we had to&nbsp;&nbsp; better understand what it means for our business.&nbsp; It seemed like it could have a really meaningful&nbsp;&nbsp; impact on the whole customer service industry,&nbsp; so we formed a small working group and explored&nbsp;&nbsp; what ChatGPT is good at, what it’s bad at, and&nbsp; what it might mean for our business. After going&nbsp;&nbsp; through that exercise, my own fears and&nbsp; worries and the hype went down a little&nbsp;&nbsp; bit. It seems like the tech is not quite there&nbsp; yet to take our jobs and automate everything. Turns out, it’s really good at some things,&nbsp; but not at everything. It’s good at,&nbsp;&nbsp; for example, things like summarizing content&nbsp; or understanding language and editing and&nbsp;&nbsp; creative writing. But it has a major flaw of&nbsp; hallucinations, where it just makes up stuff that&nbsp;&nbsp; sounds very real but is factually incorrect, which&nbsp; is obviously a big problem for a customer service&nbsp;&nbsp; solution. You don’t want to give plausibly&nbsp; sounding, but factually incorrect answers.&nbsp;&nbsp; But there are lots of interesting things you can&nbsp; apply it to. And I think the big takeaway is that&nbsp;&nbsp; this technology is evolving really fast. And&nbsp; it’s really only a matter of time before it can&nbsp;&nbsp; give factually correct answers. And once that&nbsp; happens, it’s going to be really disruptive. Emmet: So, what you’re saying is&nbsp;&nbsp; it will give an answer no matter what. And&nbsp; in some cases, this results in what you&nbsp;&nbsp; called hallucinations. Molly, this seems like&nbsp; one big limitation for anyone trying to use&nbsp;&nbsp; this for real. What are hallucinations and&nbsp; why are they happening in the first place? Molly: Yeah, it’s a huge problem, as Gustavs said.&nbsp;&nbsp; The model wants to please you, so it wants to&nbsp; give you an answer that it thinks you want.&nbsp;&nbsp; Sometimes, it has a reliable source for&nbsp; that information, and sometimes, it’s just&nbsp;&nbsp; making things up. It feels like a&nbsp; child. “Why did you do that?” “Well,&nbsp;&nbsp; I thought that was what you wanted.” The&nbsp; hallucination might be pulling from a lot&nbsp;&nbsp; of different sources. If you ask it a question&nbsp; about Intercom, it doesn’t necessarily know&nbsp;&nbsp; anything new. And so, it might take pieces&nbsp; of what it knows that are accurate, general&nbsp;&nbsp; knowledge from elsewhere, interpolate that and, in&nbsp; a way, try to use common sense, which, of course,&nbsp;&nbsp; it doesn’t have. It doesn’t really have reasoning&nbsp; capabilities. It uses probabilities like, “Well,&nbsp;&nbsp; this might probably function this way, so I can&nbsp; make up an answer about something about Intercom’s&nbsp;&nbsp; API,” or something like that. And as Gustavs said,&nbsp; it’s super plausible. It sounds very confident. And as you mentioned, different companies&nbsp; are focusing on different things. There are&nbsp;&nbsp; companies focusing a little bit more on how to&nbsp; minimize hallucinations. Whereas ChatGPT, I think,&nbsp;&nbsp; often focuses a lot on guardrails and ethics and&nbsp; being clear about what it’s refusing to answer. Emmet: Do you think we’ll see a&nbsp; proliferation of lots and lots of&nbsp;&nbsp; different models and you can choose the&nbsp; one that best suits the kind of trade-off&nbsp;&nbsp; between being absolutely correct&nbsp; and hallucinations that you want,&nbsp;&nbsp; or is this a problem that may just&nbsp; disappear as the models get more mature? Molly: I’m not sure it’ll disappear. But yes,&nbsp; there are already a lot of models. There are&nbsp;&nbsp; open-source models and there’s the potential to&nbsp; do what we call fine-tuning on top of a model. GPT&nbsp;&nbsp; stands for generative pre-trained transformer, so&nbsp; it generates things. It’s pre-trained on a large&nbsp;&nbsp; corpus and transformers. Different companies&nbsp; are going to focus on different things.&nbsp;&nbsp; There are open-source models, and Intercom,&nbsp; as a potential user of these models, might be&nbsp;&nbsp; able to fine-tune on top to get more specialized&nbsp; knowledge of our industry or company. The tech&nbsp;&nbsp; will also get better at using and needing&nbsp; less data to have a great model. And so,&nbsp;&nbsp; the models will get smaller and smaller and&nbsp; smaller. And potentially, at that point,&nbsp;&nbsp; it might be a lot more reasonable for&nbsp; a smaller company to create a model&nbsp;&nbsp; on their data and have it be quite specialized,&nbsp; quite knowledgeable, and very reliable. Emmet: Let’s shift gears and talk more&nbsp; specifically about design. Clearly,&nbsp;&nbsp; GPT and AI, in general, have been primarily a&nbsp; technology story, but I think ChatGPT illustrated&nbsp;&nbsp; something interesting, which is that the UI and&nbsp; the UX of all of this are very important. There&nbsp;&nbsp; seems to be a shift towards conversational UIs,&nbsp; potentially, for example. Do you think that’s&nbsp;&nbsp; true? What’s the role of design in shaping&nbsp; what we do with this tech from here, Molly? Molly: I mean, Intercom is very well&nbsp; positioned. Our business is about conversation&nbsp;&nbsp; and customer service, and people are getting&nbsp; really excited about having conversations with&nbsp;&nbsp; this tech. But what we’ve found recently is that,&nbsp; at least for the moment, there’s just so much&nbsp;&nbsp; power available in the tech that is&nbsp; actually not directly conversational,&nbsp;&nbsp; but it’s about conversation and language. As we mentioned, it’s great at summarization, and&nbsp; there are a ton of workflows where summarization&nbsp;&nbsp; can really help customer service agents. We&nbsp; have recently launched a beta to some customers,&nbsp;&nbsp; and summarization is one of the things that people&nbsp; are finding really, really, really valuable.&nbsp;&nbsp; We’ve also added some generative text tools&nbsp; to allow reps to make modifications to their&nbsp;&nbsp; messages if they want to rephrase things, make&nbsp; them friendlier, make them a little more formal,&nbsp;&nbsp; or get help clarifying things.&nbsp; That’s part of the conversation,&nbsp;&nbsp; but it’s not directly having a conversation with&nbsp; ChatGPT. We’re also finding it useful for helping&nbsp;&nbsp; generate things like help center articles,&nbsp; which was also part of this beta release.&nbsp;&nbsp; A lot of the power of this is in some of the more&nbsp; hidden applications that aren’t so obvious to lay&nbsp;&nbsp; people but are really time-consuming for reps.&nbsp; And we can provide a lot of value with that. Gustavs: Yeah. There are many ways&nbsp; you can use this technology, and&nbsp;&nbsp; through that, sidestep some of the problems&nbsp; we’ve seen, specifically with hallucinations,&nbsp;&nbsp; where it’s making up stuff that is not correct.&nbsp; But it’s really good at other things. It’s good at&nbsp;&nbsp; re-wording existing content, and it makes sense to&nbsp; lead with that because it can deliver clear value.&nbsp;&nbsp; The end goal would be to be completely&nbsp; automated and actually give answers.&nbsp;&nbsp; It’s just that the tech is not good enough&nbsp; for that yet. But I think we’ll get there. Emmet: And I suspect that’s how we’ll see&nbsp; things throughout 2023 because I imagine&nbsp;&nbsp; we’ll start to see this creep its way into lots of&nbsp; different products, probably in relatively simple,&nbsp;&nbsp; foolproof ways to begin with and then increasingly&nbsp; pushing the boat out in terms of the complexity of&nbsp;&nbsp; what it can do. We have all, I think, approached&nbsp; this opportunity with a combination of excitement&nbsp;&nbsp; and maybe a little bit of healthy trepidation as&nbsp; well. Molly, you mentioned we have these features&nbsp;&nbsp; backed by ChatGPT in beta at the moment. And&nbsp; the feedback has been extremely heartening&nbsp;&nbsp; and positive. The earliest signs we’re seeing are&nbsp; real customers getting real utility from features&nbsp;&nbsp; like summarizing a conversation before handing&nbsp; it over to someone else. You’re looking for that&nbsp;&nbsp; intersection of things that the tech is good at&nbsp; and things where there’s a relatively low risk.&nbsp;&nbsp; And we’ll see a lot of those in the months&nbsp; to come. So, that’s going to be exciting. Emmet: Gustavs, you’ve been thinking&nbsp; about this more in the long-term view.&nbsp;&nbsp; Could you speak to that a little bit? You&nbsp; mentioned Intercom – one of the reasons we’re&nbsp;&nbsp; here talking about this is we’re probably pretty&nbsp; well positioned, given the nature of our products,&nbsp;&nbsp; which is conversational customer&nbsp; service, to make the most of this.&nbsp;&nbsp; What do you think when you think about&nbsp; long-term product and design opportunities? Gustavs: In the very early days of the ChatGPT&nbsp; launch, we did this workshop to try and think&nbsp;&nbsp; through the future, specifically about how the&nbsp; world would look like if we had a model that&nbsp;&nbsp; didn’t have this hallucination problem and was&nbsp; able to give good answers or say “I don’t know.”&nbsp;&nbsp; It’s been really promising, and it has really&nbsp; increased our confidence in a lot of things we&nbsp;&nbsp; already believed in but are getting accelerated.&nbsp; We believe that the majority of support queries&nbsp;&nbsp; will be resolved completely automatically without&nbsp; talking to humans. It’s already increasing today&nbsp;&nbsp; with more of the “if this, then that” type of&nbsp; builders, with bots and our own resolution bot,&nbsp;&nbsp; which has some machine learning capabilities&nbsp; but not to the same extent as ChatGPT. We’re already on that path, but it’s going to get&nbsp; accelerated. And as a result of that, support orgs&nbsp;&nbsp; will start to shift from being reactive and&nbsp; primarily in the inbox to being proactive –&nbsp;&nbsp; setting up and training the AI; writing content&nbsp; that the AI can use to resolve conversations. I think the majority of support&nbsp; will happen in a way that’s most&nbsp;&nbsp; natural to humans, which is through&nbsp; conversation. Imagine if you had&nbsp;&nbsp; someone you can always talk to that has a&nbsp; personalized answer just for you. That’s the&nbsp;&nbsp; most natural way for humans to interact. This&nbsp; search and browse experience we have today,&nbsp;&nbsp; where you search for something on Google and scan&nbsp; it to try and quickly find answers somewhere in&nbsp;&nbsp; the content, is not that natural for humans. There&nbsp; are still going to be some versions of that with&nbsp;&nbsp; suggestions for content that might be relevant&nbsp; for you before you start a conversation.&nbsp;&nbsp; But when you interact with it,&nbsp; it could still be conversational. We believe we’ll also need to&nbsp; build a bridge to get there&nbsp;&nbsp; for multiple reasons. I think we’ll start by&nbsp; seeing support rep augmentation with things like&nbsp;&nbsp; summarization or rephrasing. Later, we’ll get into&nbsp; suggestions for replies that support reps can edit&nbsp;&nbsp; and improve upon, and later, we’ll get into full&nbsp; automation. It’s going to take a while, both for&nbsp;&nbsp; the tech and the human aspect of it as well,&nbsp; to get used to using more and more automation. Emmet: You’re describing something where, across a&nbsp; very broad surface area of the product, there are&nbsp;&nbsp; lots of different places where this can change how&nbsp; we work, both what we call the teammate experience&nbsp;&nbsp; and the end-user experience, in the two sides of&nbsp; the conversation. But you’re also describing this&nbsp;&nbsp; cloudy notion of how we’re going to get&nbsp; to this vague future of “we think the&nbsp;&nbsp; tech will get there.” It strikes me&nbsp; as a very different way of thinking&nbsp;&nbsp; about approaching design today and&nbsp; almost a profound difference in how&nbsp;&nbsp; we think about interacting with computers,&nbsp; going from something very deterministic,&nbsp;&nbsp; very hard-edged – of true and false and&nbsp; ones and zeros – to something way fuzzier. Emmet: Designers are now looking&nbsp; at working with this material that&nbsp;&nbsp; feels way more unknowable and plastic and less&nbsp; rigid than CRUD apps, “create, write, update,&nbsp;&nbsp; delete,” that we have been used to. What have you&nbsp; found? Is there a substantial difference in how&nbsp;&nbsp; designers need to approach their work? Have you&nbsp; found certain things difficult or challenging?&nbsp;&nbsp; Will designers have to learn new skills? How big&nbsp; of a change is this for the act of designing, the&nbsp;&nbsp; fact that the material we’re designing with almost&nbsp; has this element of unknowability baked into it? Molly: I think there’s still a lot about&nbsp; our job that’s going to stay the same.&nbsp;&nbsp; We’re finding problems, digging around people’s&nbsp; workflows, finding patterns. One big thing is&nbsp;&nbsp; needing to design for a lot more failure cases&nbsp; because there aren’t necessarily guardrails. When&nbsp;&nbsp; you’re having a conversation, it can go off the&nbsp; rails in so many different ways. And it’s the same&nbsp;&nbsp; with a system like this. Humans, as a species, are&nbsp; not great at probabilities. When we look at the&nbsp;&nbsp; weather report and there’s a 40% chance of rain,&nbsp; we don’t have a great sense of what that means. Emmet: Yeah, you’re disappointed if it doesn’t&nbsp; rain because you were told there’d be rain. Molly: Yeah. I’m in the Netherlands – when&nbsp; I see any chance of rain, I’m like, “It will&nbsp;&nbsp; rain. It’s just a question of how long.” That’s&nbsp; what the percentages mean to me. But we’re not&nbsp;&nbsp; that great at interpreting them. I think that’s&nbsp; definitely going to be something as we look at how&nbsp;&nbsp; confident these predictions are because they’re&nbsp; predictions of what words should come next.&nbsp;&nbsp; And we’ll look to get better at that. There’s&nbsp; a lot of dealing with how fast this tech moves&nbsp;&nbsp; and changes, and I don’t think that’s going&nbsp; to change. There’s a lot of prototyping and&nbsp;&nbsp; reacting and thinking about latency. The latency&nbsp; right now can be quite long – designing for that.&nbsp;&nbsp; And there are a lot of unexpected results.&nbsp; Those are some of the things I’ve been noticing. Gustavs: I think, over time, we’ll see more and&nbsp; more new design patterns emerge for how to manage&nbsp;&nbsp; this uncertainty and expectations on all sides. At&nbsp; the moment, everyone is experimenting and seeing&nbsp;&nbsp; what works. We’re already seeing some patterns&nbsp; emerging with small predefined prompts on how&nbsp;&nbsp; to change text like “expand this,” “summarize&nbsp; this,” “make it friendlier.” It’s a relatively&nbsp;&nbsp; new pattern that is starting to emerge, and I&nbsp; think we’ll see more and more of those types of&nbsp;&nbsp; patterns. Even this interaction where, if you&nbsp; ask ChatGPT to generate content, it has this&nbsp;&nbsp; slowly moving cursor. That’s an interesting design&nbsp; pattern as well. It’s technically required, but it&nbsp;&nbsp; could work really well to set expectations that,&nbsp; “hey, this is AI generating content on the fly.” Emmet: So, you’re saying that this word-by-word,&nbsp; ticker-tape typing effect, which is, to be clear,&nbsp;&nbsp; a function of how the technology makes it up&nbsp; word by word, could become synonymous and a&nbsp;&nbsp; visual calling card. Maybe that’ll happen, maybe&nbsp; not, but the type of thing that tends to emerge&nbsp;&nbsp; when we see these shifts and new technologies&nbsp; emerging might be interesting to drill down into&nbsp;&nbsp; the idea of new design patterns emerging because&nbsp; we do see this when new technologies come along.&nbsp;&nbsp; Molly, are there others that you’ve&nbsp; encountered, either at a very low&nbsp;&nbsp; interaction design level or at the high level&nbsp; of how this gets stitched into products? Molly: There are a couple of other things that I&nbsp; think will start showing up more. For instance,&nbsp;&nbsp; when we’re trying to develop a feature, engineers&nbsp; are doing backtesting. They’re using past&nbsp;&nbsp; data and making predictions on that and then&nbsp; comparing it to what a teammate actually said,&nbsp;&nbsp; for instance. For things like that, we might need&nbsp; to start launching not on the end user but on the&nbsp;&nbsp; teammate or admin side, where people managing a CS&nbsp; org might want to have what I call a dark launch –&nbsp;&nbsp; they don’t have things live but are able&nbsp; to watch them and get a sense of, “Okay,&nbsp;&nbsp; I now trust this to go.” Varying stages&nbsp; of dark launches, draft suggestions,&nbsp;&nbsp; and different stages of launching some of&nbsp; these tools. I think that’ll be more prominent. I don’t know which direction&nbsp; it’ll go, but I think about&nbsp;&nbsp; points where we might have to add friction back&nbsp; into the system so we don’t get complacency.&nbsp;&nbsp; Pilots still do certain portions of a flight,&nbsp; even though the autopilot system does most of it,&nbsp;&nbsp; because they need to not forget how to fly.&nbsp; So, they’re doing the landings or other things.&nbsp;&nbsp; In these new systems that might be very&nbsp; automated, are we thinking about adding&nbsp;&nbsp; some friction back in so we retain the skills&nbsp; that feel valuable and that we want to have? Emmet: And clearly, almost everything has&nbsp; an implicit confidence score for the feature&nbsp;&nbsp; built into it that you have to design. Is this&nbsp; something we would expose to the reps and admins&nbsp;&nbsp; or their customers? There’s a higher threshold&nbsp; for us for exposing stuff to their customers&nbsp;&nbsp; or even at a lower level of detail. Take the&nbsp; ability to summarize a long conversation. Do&nbsp;&nbsp; you post that summarization straight into the&nbsp; conversation thread at the click of a button,&nbsp;&nbsp; or do you give someone the opportunity to review&nbsp; and approve it? Let it straight through versus&nbsp;&nbsp; adding an approval gate? I think we’ll probably&nbsp; see lots of workflows emerge, at least initially,&nbsp;&nbsp; and then, do they just start falling off as&nbsp; the tech builds greater and greater confidence? Molly: Yeah, exactly. Gustavs: Even just the ability to tell you&nbsp; how confident it is. If the AI could tell you,&nbsp;&nbsp; “Hey, this is my answer, and it’s 40%&nbsp; correct,” you might present it for a&nbsp;&nbsp; human to approve before it gets sent. If it’s&nbsp; 90% confident, you can just go ahead and send&nbsp;&nbsp; it straightaway and have a “hey, this is&nbsp; incorrect” button on the end user’s side.&nbsp;&nbsp; It really depends on how the tech evolves.&nbsp; The design will have to evolve alongside it. Emmet: Yeah. God, grant me the confidence&nbsp; of a large language model because it will&nbsp;&nbsp; absolutely confidently say a total falsehood&nbsp; and the total truth without distinguishing&nbsp;&nbsp; between them. And that’s the trust thing. At&nbsp; the moment, there’s nothing that says, “I’m&nbsp;&nbsp; 100% confident in this statement.” In ChatGPT,&nbsp; at least. In some of the other language models,&nbsp;&nbsp; I believe we’re starting to see sources&nbsp; referenced, which seems a positive step. Emmet: It seems like there are lots of&nbsp; unknown things, lots of nitty-gritty,&nbsp;&nbsp; deep-design decisions like this to get involved&nbsp; in. Let’s zoom out to what these megatrends&nbsp;&nbsp; mean for design and product. People have&nbsp; witnessed or been a part of the arrival of big,&nbsp;&nbsp; new technologies. I’m thinking about things&nbsp; like the cloud or massively shifting to web&nbsp;&nbsp; and mobile as big enabling technologies&nbsp; that led to this whole new world of&nbsp;&nbsp; design patterns and products that were&nbsp; not available before. With the cloud,&nbsp;&nbsp; we saw forms and feeds and likes and all of the&nbsp; visual transformation that the web went through. You could say a lot of the same&nbsp; for mobile – everything from&nbsp;&nbsp; feeds and hamburger menus to pull to refresh&nbsp; and swipe to delete that we now consider&nbsp;&nbsp; part of a designer’s toolkit. Maybe we’re getting&nbsp; dangerously close to prediction time, but what is&nbsp;&nbsp; your early experience working with this? Does it&nbsp; tell you anything about what types of products are&nbsp;&nbsp; going to win or lose and what new things we might&nbsp; see emerging that weren’t even possible before? Gustavs: I think, over time, most&nbsp; businesses will be using these&nbsp;&nbsp; publicly available large language models instead&nbsp; of creating their own. But to differentiate from&nbsp;&nbsp; one another, they might build layers on&nbsp; top of them with specialized knowledge.&nbsp;&nbsp; For example, you might have business-specific&nbsp; data – for a support tool, it could be answers&nbsp;&nbsp; to specific questions about your product and your&nbsp; support reps giving specific answers as opposed to&nbsp;&nbsp; generalized knowledge. It could be really deep&nbsp; knowledge of a particular field, such as law. The businesses that are going to win, I&nbsp; think, are the ones that will have some&nbsp;&nbsp; sort of proprietary data and a flywheel effect&nbsp; continuously gathering and improving that data.&nbsp;&nbsp; The other thing I think is going to be interesting&nbsp; is seeing what the big players like Google,&nbsp;&nbsp; Apple, and Microsoft do with this technology&nbsp; and how they integrate it into the OS level.&nbsp;&nbsp; That could have a huge impact on what kind&nbsp; of niches are available for other businesses. Emmet: You started off by saying most people&nbsp; are going to integrate these large language&nbsp;&nbsp; models in a certain way. I think that businesses&nbsp; that don’t manage to do what you were saying,&nbsp;&nbsp; and actually find some kind of defensive moat,&nbsp; will find themselves basically a thin wrapper&nbsp;&nbsp; over GPT that doesn’t really do a lot else. So,&nbsp; I fully agree with you there. If you think about&nbsp;&nbsp; something like the App Store or mobile app stores,&nbsp; there were lots of toys and flashlights and things&nbsp;&nbsp; like that in the early days. And then, gradually,&nbsp; it shakes out into big enabling things like&nbsp;&nbsp; Uber, which couldn’t exist if we didn’t have&nbsp; this model, and Instagram and mapping and so on.&nbsp;&nbsp; Molly, anything that you would like&nbsp; to add based on your experience? Molly: I’m not totally sure that&nbsp; everyone will be using public&nbsp;&nbsp; LLMs. I have a small fear they’ll either&nbsp; be too expensive for a lot of companies&nbsp;&nbsp; to make their business model work or that some&nbsp; of the large companies might keep them private.&nbsp;&nbsp; So, I’m not sure if everyone will be using&nbsp; public ones or if people will move more toward&nbsp;&nbsp; open source and put their fine-tuned layer on&nbsp; top. I agree about the data modes. For instance,&nbsp;&nbsp; at Intercom, we have a lot of conversational&nbsp; data and we’re able to do things that Apple can’t&nbsp;&nbsp; necessarily do on an OS level. And that provides&nbsp; us some value. I think the products that’ll be&nbsp;&nbsp; successful are going to be the ones that, as&nbsp; you said, aren’t just a commodity layer on top,&nbsp;&nbsp; but deeply understand a problem or workflow&nbsp; and can integrate that with their data mode. Emmet: You also touched on a couple&nbsp; of things that, for the time being,&nbsp;&nbsp; are going to be important around&nbsp; limitations. It is slow. It takes seconds&nbsp;&nbsp; to return a response. There are going to be some&nbsp; products or spaces where it’s just unsuitable.&nbsp;&nbsp; It’s also expensive in terms of computing power&nbsp; and therefore expensive in terms of money.&nbsp;&nbsp; You probably know more than me about this, but&nbsp; every request costs a couple of cents. OpenAI&nbsp;&nbsp; is losing millions a day to run ChatGPT, and&nbsp; it’s probably worth it from a PR point of view&nbsp;&nbsp; or whatever research data they’re garnering,&nbsp; but it also means it’s not going to be free and&nbsp;&nbsp; leisured. And while technology has a very good&nbsp; habit of getting faster and cheaper over time,&nbsp;&nbsp; and this potentially could happen here, for&nbsp; the time being, there are certain limitations&nbsp;&nbsp; that restrict the application. Maybe we’ll see it&nbsp; less in real-time apps. Maybe we’ll see it less in&nbsp;&nbsp; B2C apps, where the scale and cost of&nbsp; running those kinds of queries could&nbsp;&nbsp; be massive. It’s going to be interesting&nbsp; to see how things emerge there as well. Emmet: I’m curious to go deeper in terms of the&nbsp; design conversation and actually think about&nbsp;&nbsp; these generative systems and how we are going&nbsp; to interact with them. We’re alluding to all&nbsp;&nbsp; the new taps and swipes and things you can&nbsp; do when a new platform comes along. This is&nbsp;&nbsp; where we will inevitably have to tiptoe&nbsp; our way into the world of prediction.&nbsp;&nbsp; We can all look back at this in a year or&nbsp; two’s time and laugh at how wrong we are, but&nbsp;&nbsp; there’s an interesting sense that maybe this&nbsp; is shifting towards more of a text-based,&nbsp;&nbsp; almost command-line-based way of interacting.&nbsp; Another kind of micro trend in product has been&nbsp;&nbsp; this command + k pallete that you can pop&nbsp; up by hitting a shortcut and typing in the&nbsp;&nbsp; action you want to take. We see that in lots of&nbsp; products, which is contributing to this general&nbsp;&nbsp; sense of a shift towards text and natural&nbsp; language as a direct way of interfacing. On the other hand, if you look at previous trends,&nbsp; especially the journey we went through from the&nbsp;&nbsp; command line interface, we ended up building very&nbsp; detailed graphical user interfaces on top. And so,&nbsp;&nbsp; I wonder if you would care to speculate&nbsp; as to where you see this going. Does this&nbsp;&nbsp; auger a shift toward more command-line&nbsp; interfaces for the 21st century? Is this&nbsp;&nbsp; a temporary command-line thing before&nbsp; we figure out what a graphical user&nbsp;&nbsp; interface layer on these things looks&nbsp; like? Is it just too damn early to say? Gustavs: Well, I think we’ll have all of&nbsp; those. I don’t think we have to pick one&nbsp;&nbsp; way for interacting with AI. It’s a very broad&nbsp; capability that can be applied in different ways&nbsp;&nbsp; for different use cases. So, for example, if&nbsp; you’re looking for an answer, conversation will&nbsp;&nbsp; be the primary way for getting an answer. But if&nbsp; we’re talking about workflow augmentation with AI,&nbsp;&nbsp; I think we’ll see graphical interfaces with&nbsp; predefined actions for AI to take. It’s the same&nbsp;&nbsp; as we’re seeing today with summarize,&nbsp; rephrase, and the whole wave of co-pilot for X. With workflow automation, I mean using AI to&nbsp; improve how you do your work. So, for example,&nbsp;&nbsp; in customer support, it’s when you’re writing&nbsp; replies to customers using AI to improve those&nbsp;&nbsp; replies. Again, expanding a point or summarizing&nbsp; the conversation up until that point. I think&nbsp;&nbsp; there could be graphical interfaces for&nbsp; those types of workflow augmentation. Molly: I’m terrible at predictions, but&nbsp; we might have kind of a proliferation of,&nbsp;&nbsp; as you said, command + K interfaces or different&nbsp; options of what you can do. One of the challenges&nbsp;&nbsp; with this tech is the discoverability of what it&nbsp; can do. You can type anything into this prompt.&nbsp;&nbsp; “Write me a Shakespearean poem like a pirate,”&nbsp; or something. We’ll be putting some guardrails,&nbsp;&nbsp; but I think we’ll probably go broad and then&nbsp; see things narrow down a bit as things get&nbsp;&nbsp; more common and useful. And then, eventually,&nbsp; maybe be able to go to more of a text-based&nbsp;&nbsp; or conversational-based or wide-open interface&nbsp; once we have a sense of what this tech can do. As we get used to talking to our systems,&nbsp; I’m also excited about the potential for&nbsp;&nbsp; neural interfaces. Why talk about it if I&nbsp; can just think it? I know that’s a ways off,&nbsp;&nbsp; but when I was at Berkeley, some of my colleagues&nbsp; were working on that. It would be really cool.&nbsp;&nbsp; There are a lot of situations where you don’t want&nbsp; to talk and type, and this opens things up. Maybe&nbsp;&nbsp; farther in the future, we’ll have integrated&nbsp; systems that can take non-gooey instructions&nbsp;&nbsp; and translate them into actions. We’re already&nbsp; seeing that with some of these systems that can&nbsp;&nbsp; take natural language queries and instructions&nbsp; and turn them into actions on your computer.&nbsp;&nbsp; And the fact is that some of these LLMs are&nbsp; also really good at generating code, like&nbsp;&nbsp; GitHub co-pilot. And so, there’s&nbsp; just a lot of potential there. Emmet: I suspect text manipulation is going to&nbsp; have a great year in software because there’s&nbsp;&nbsp; so much immediate possibility here.&nbsp; It feels very natural to be able to&nbsp;&nbsp; highlight a piece of text and say, “make this&nbsp; friendlier.” It almost feels like that belongs&nbsp;&nbsp; in the tool palette alongside bold and italic.&nbsp; It’s just a way of manipulating the existing text.&nbsp;&nbsp; Then, there are lots of ways of taking that&nbsp; further, like generation or code generation. I personally found the experience of working&nbsp; with image generators to be quite different.&nbsp;&nbsp; Again, a lot of our experience of these&nbsp; systems is seeing the results scroll by,&nbsp;&nbsp; like screenshots of ChatGPT or something that&nbsp; DALL-E, Midjourney, or Stable Diffusion created.&nbsp;&nbsp; The creation process of the image generators feels&nbsp; clunky to me, and something that will likely be&nbsp;&nbsp; gooey-fied and have a much more tactile on-screen&nbsp; interface. Having to just stuff the prompt with&nbsp;&nbsp; short F-stop trending on deviant art to try&nbsp; and get it to create the outputs you want is so&nbsp;&nbsp; clearly a hack. And there are lots of dimensions&nbsp; of different styles that you want to go through&nbsp;&nbsp; that would be way better served by knobs and dials&nbsp; and sliders of some sort. I guess my prediction&nbsp;&nbsp; is we’ll see prompt engineering as it exists today&nbsp; be replaced by something hopefully much better. And just to finish the thought, video and audio&nbsp; are very different because you have to sit down&nbsp;&nbsp; for a long time and review the results. You can&nbsp; eyeball a hundred images or skim reads some text,&nbsp;&nbsp; but I honestly have fewer opinions on that because&nbsp; I’ve been able to sink less time into it. But I&nbsp;&nbsp; guess it gets back to what you were ultimately&nbsp; saying, Gustavs. It’s not a satisfying answer,&nbsp;&nbsp; but it’s going to depend massively. And&nbsp; I think it’ll depend a lot on what’s the&nbsp;&nbsp; thing I’m manipulating. And we might have&nbsp; very different UIs for that depending. Gustavs: At the same time, I think there are&nbsp; going to be new interesting applications of&nbsp;&nbsp; giving natural language instructions. For&nbsp; example, one thing we found interesting&nbsp;&nbsp; when we did our initial exploration was that&nbsp; the way you could train AI could be very,&nbsp;&nbsp; very similar or practically the same as if the&nbsp; AI was a support agent and you would give them&nbsp;&nbsp; feedback about your policy on how to interact&nbsp; with customers or what tone of voice to use.&nbsp;&nbsp; Even when you’re giving feedback on individual&nbsp; conversations, you could just give those in plain&nbsp;&nbsp; text because it understands natural language and&nbsp; the context. I think we’ll see that as well. And&nbsp;&nbsp; there’s something interesting about the&nbsp; AI being like a super-powered colleague&nbsp;&nbsp; that can use the tools you have and you can give&nbsp; them plain text feedback to help improve them. Emmet: Molly touched on what happens when&nbsp; these things don’t just spit out text,&nbsp;&nbsp; but can take actions as well, for example.&nbsp; And that’s probably a whole additional&nbsp;&nbsp; level of what they’re capable of. Molly: Fergal, for those of you who listen to&nbsp; some earlier podcasts, is the director of Machine&nbsp;&nbsp; Learning. He says that his ideal for an ML system&nbsp; should be like an intelligent colleague sitting&nbsp;&nbsp; next to you whom you can give instructions&nbsp; and it’s going to actually execute it well.&nbsp;&nbsp; That’s kind of the dream. And so, as Gustavs said,&nbsp;&nbsp; being able to give natural language feedback is&nbsp; just this sea change in how we can manage it. Emmet: I wonder even how much of a range&nbsp; there’ll be. There was an agency called&nbsp;&nbsp; Berg in London a few years back, and they did&nbsp; lots of experiments with earlier iterations of&nbsp;&nbsp; AI. But one of their principles was “be as smart&nbsp; as a puppy” because they didn’t want the AI to&nbsp;&nbsp; feel threatening or overwhelming. And that was&nbsp; their principle on drawing boundaries around us.&nbsp;&nbsp; I don’t like carving out designers as the&nbsp; finger-wagging “you can’t do that” type,&nbsp;&nbsp; but maybe setting those safe boundaries is an&nbsp; important role for designers to play as well. Molly: I think there’s a role for those&nbsp; boundaries. I do want to work next to a puppy,&nbsp;&nbsp; but do you want to work next to someone with&nbsp; the intelligence of a puppy? I think the role of&nbsp;&nbsp; designers is: how do we make this intelligent,&nbsp; could-potentially-be-threatening colleague,&nbsp;&nbsp; a teammate who is making you better, that&nbsp; can have this really great whiteboarding,&nbsp;&nbsp; brainstorming session where you’re just&nbsp; riffing off each other? How do we get&nbsp;&nbsp; to that? That’s where we can really add&nbsp; this magic – making the workday better,&nbsp;&nbsp; augmenting workflows, and making&nbsp; AI an actual teammate for people. Emmet: Self-driving cars are probably the&nbsp; most advanced application currently of AI,&nbsp;&nbsp; even though it’s not at a broad adoption&nbsp; level. The tension of these levels of&nbsp;&nbsp; self-driving and the increasing risk&nbsp; as you go through those levels –&nbsp;&nbsp; a version of that probably applies to a&nbsp; lot of these things, if you think about it. Molly: Yeah, I mean, that’s exactly what we&nbsp; already mentioned. Is it a suggestion? Is&nbsp;&nbsp; there a review? Is there approval? That’s just our&nbsp; version of the five levels of autonomous vehicles. Gustavs: Another thing that’s&nbsp; interesting is that, over time,&nbsp;&nbsp; as the AI gets better and is able to not just give&nbsp; answers but also perform actions on your behalf,&nbsp;&nbsp; similar to how a colleague might, it’s going to&nbsp; be an interesting design challenge to figure out&nbsp;&nbsp; a way to make it feel like someone sitting&nbsp; next to you and helping you, as opposed to a&nbsp;&nbsp; hacker hijacking your computer and clicking around&nbsp; things. If you can make it work with design, it’s&nbsp;&nbsp; going to feel magical. Or it could be crazy scary.&nbsp; It’s going to be an interesting design challenge. Emmet: And it’s possible that the&nbsp; conversational route is the best&nbsp;&nbsp; way to do that. The degree to which it’s framed&nbsp; as a person that’s friendly and conversational&nbsp;&nbsp; versus the system that you interact with at&nbsp; a distance will also be interesting to see. A couple of years ago, we had what, in&nbsp; retrospect, you could think of as a bot hype&nbsp;&nbsp; cycle. And actually, Intercom was quite actively&nbsp; involved in experimenting and finding out what&nbsp;&nbsp; we could do. Of course, we have products that took&nbsp; advantage of that, as we mentioned already. Things&nbsp;&nbsp; like the resolution bot and custom bots. But we&nbsp; also found during that hype cycle that there are a&nbsp;&nbsp; whole bunch of applications that are not good for&nbsp; conversational UI at all. There was a weather bot,&nbsp;&nbsp; and you’re like, “Actually, I don’t need a bot&nbsp; to ask what the weather is – I have an app or&nbsp;&nbsp; a webpage that’s fine for that.” We’ll inevitably&nbsp; see a lot of that happen here as well. Probably an&nbsp;&nbsp; over-application of conversational UI, but then&nbsp; the truly useful use cases coming to the fore. One additional thing I’ll add that makes me&nbsp; quite bullish on the conversational thing is&nbsp;&nbsp; a problem we’ve been working on for a long time.&nbsp; The Turing test is not new. But aside from that,&nbsp;&nbsp; I worked at Google several years ago. There was&nbsp; a massive amount of work in search and pride in&nbsp;&nbsp; getting it to answer a question like, “How tall&nbsp; is the Eiffel Tower?” Something that just seems&nbsp;&nbsp; super basic in comparison to what we now have&nbsp; available to us. Even voice assistants like&nbsp;&nbsp; Siri suddenly woke up one morning in&nbsp; late November to be almost obsolete. The speed at which the systems get better&nbsp; will really drive a large part of this,&nbsp;&nbsp; as well. One of the interesting and new things for&nbsp; designers is we’re along for the ride to a greater&nbsp;&nbsp; degree than us working with web technologies or&nbsp; whatever in the past. Where the technology goes&nbsp;&nbsp; from here is going to dictate things as much as&nbsp; our directorial authorial vision as designers. One last dimension I think about&nbsp; in terms of design, specifically,&nbsp;&nbsp; is the tools that we use and the&nbsp; fact that they have the potential&nbsp;&nbsp; to change dramatically. Will the nature&nbsp; of the production and the ideation work&nbsp;&nbsp; change a lot? Will we have to learn new&nbsp; skills like prompt engineering? Gustavs,&nbsp;&nbsp; any high-level thoughts on what this means for&nbsp; the changing nature of actually doing design? Gustavs: Yeah. In terms of prompt engineering&nbsp; specifically, I think, over time, we’ll see&nbsp;&nbsp; an emergence of best practices for how&nbsp; to do that in the same way we have for&nbsp;&nbsp; any other technology. And obviously, they’ll&nbsp; evolve and get better over time, but I don’t&nbsp;&nbsp; think it’s going to be a key differentiator that&nbsp; is going to fundamentally shape your business.&nbsp;&nbsp; It’s difficult to tell how the role of the&nbsp; designer will change, and it depends on the&nbsp;&nbsp; timeframe. In the short term, I think it’s&nbsp; going to be really important for designers to&nbsp;&nbsp; lean into this and just play around and&nbsp; tinker with these language models and see&nbsp;&nbsp; how you can apply them to your product,&nbsp; how other businesses are applying it to&nbsp;&nbsp; theirs, and try to find patterns and&nbsp; interesting ways of doing new things. But over the long term, it’s way more difficult to&nbsp; tell what the impact is going to be on designers&nbsp;&nbsp; in the whole industry. So, as the AI gets better,&nbsp; and not just at augmenting humans, but also at&nbsp;&nbsp; doing full automation of writing and performing&nbsp; tasks, I think that can fundamentally disrupt&nbsp;&nbsp; a lot of products and industries and even the&nbsp; role designers play in shaping those products. I&nbsp;&nbsp; guess we’ll see. Lots of open questions, and it’s&nbsp; going to be interesting to see how it plays out. Emmet: Yeah. One of the nice things about doing&nbsp; what we do is that occasionally, technology gifts&nbsp;&nbsp; you with a whole new kind of avenue that you&nbsp; can pursue. This definitely feels like it’s&nbsp;&nbsp; a thing that is going to substantially alter the&nbsp; landscape that we work in and create a ton of new&nbsp;&nbsp; challenges and opportunities for designers. For us&nbsp; at Intercom, it’s very exciting to be well along&nbsp;&nbsp; the way and on that path and fully committed&nbsp; to it. It’s going to be an interesting year&nbsp;&nbsp; for AI and designing with AI, no doubt. I’m&nbsp; looking forward to seeing where we get to it.&nbsp;&nbsp; Maybe we can leave it at that. Molly, thank&nbsp; you very much. Gustavs, thanks a million. It&nbsp;&nbsp; was great chatting with you and learning from&nbsp; your earlier experience working with this tech.&nbsp;&nbsp; Maybe we’ll do it again when we’re all older&nbsp; and wiser, but for now, thanks very much.